ğŸ“ License
This project is open-source. Use freely!

ğŸ’¬ Author

Abhishek Kumar Vishvakarma!
Feel free to connect or contribute!


ğŸš€ LangChain + Ollama Local Chatbot (Streamlit UI)

A simple and powerful AI chatbot built using LangChain, Ollama (Local LLM), and Streamlit.
This app lets you chat with a completely offline AI model like Llama 3, running on your local machine.


â­ Features

ğŸ§  Local AI Model using Ollama (no API required)
ğŸ§© LangChain-powered prompt pipeline
ğŸ’¬ Chat history support
âš¡ Fast inference
ğŸ¨ Beautiful & clean Streamlit UI
ğŸ”’ Works offline, no data leaves your system


ğŸ“ Project Structure
project-folder/
â”‚-- app.py
â”‚-- requirements.txt
â”‚-- .gitignore
â”‚-- README.md
â””â”€â”€ (venv)   # Not included in Git


ğŸ› ï¸ Installation
1ï¸âƒ£ Clone the repository
git clone https://github.com/YOUR-USERNAME/YOUR-REPO.git
cd YOUR-REPO

2ï¸âƒ£ Create a virtual environment
python -m venv venv

3ï¸âƒ£ Activate the virtual environment
Windows:
venv\Scripts\activate

Mac/Linux:
source venv/bin/activate

ğŸ“¦ Install Dependencies
pip install -r requirements.txt

ğŸ¤– Install Ollama & Model

Download Ollama:
https://ollama.com/download

Pull the model (Llama 3 recommended):

ollama pull llama3

â–¶ï¸ Run the Chatbot
streamlit run app.py


Then open the browser link shown in terminal (usually):

http://localhost:8501